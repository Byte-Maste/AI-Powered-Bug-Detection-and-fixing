{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4c3b960b475044958b449b9bc32d1371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ad8b1994f5b4481b3d7531896e7e23f",
              "IPY_MODEL_8e989afbb14e4d6ea3c1368449e0cc1c",
              "IPY_MODEL_e4a6c8260d1e44b1945aa3a4ae0ab201"
            ],
            "layout": "IPY_MODEL_f8b37b12e16143ea813475fbaf9d7186"
          }
        },
        "4ad8b1994f5b4481b3d7531896e7e23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a775a65ac5a48b7bb5994039b33e338",
            "placeholder": "​",
            "style": "IPY_MODEL_016c5739d41a47d3a14ddbbcba919f57",
            "value": "Map: 100%"
          }
        },
        "8e989afbb14e4d6ea3c1368449e0cc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdd48c9cf55c431aada1efeb07d1530b",
            "max": 25793,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ddc35a990034996aaec4e2610bf950c",
            "value": 25793
          }
        },
        "e4a6c8260d1e44b1945aa3a4ae0ab201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c58daa7ad24314adb0e2f69f226c34",
            "placeholder": "​",
            "style": "IPY_MODEL_7d5836138943463eaec2d05ca48e21c8",
            "value": " 25793/25793 [00:00&lt;00:00, 85721.49 examples/s]"
          }
        },
        "f8b37b12e16143ea813475fbaf9d7186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a775a65ac5a48b7bb5994039b33e338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "016c5739d41a47d3a14ddbbcba919f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdd48c9cf55c431aada1efeb07d1530b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ddc35a990034996aaec4e2610bf950c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3c58daa7ad24314adb0e2f69f226c34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d5836138943463eaec2d05ca48e21c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9f1744b59f440c68ffa9c3ebd1c6254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_314719aad6794ddcba4020ee3c6554f6",
              "IPY_MODEL_44383b076f254e0dac7c52f1091a3fc9",
              "IPY_MODEL_1a4530fb1876459a91be91b25c407e82"
            ],
            "layout": "IPY_MODEL_d079a34e9da44461a4f1df46768484e8"
          }
        },
        "314719aad6794ddcba4020ee3c6554f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d2c2ea3d1484dd5b93e81d3149aea62",
            "placeholder": "​",
            "style": "IPY_MODEL_9279a17743be47f3ae31ad2b927bfbee",
            "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=2): 100%"
          }
        },
        "44383b076f254e0dac7c52f1091a3fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f000d6c1e8b5499aa6e3b115db634da8",
            "max": 25793,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b4126a513164462ba2bc19d2e5274e7",
            "value": 25793
          }
        },
        "1a4530fb1876459a91be91b25c407e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_102853408df44ad7b85b88f6caf8fe93",
            "placeholder": "​",
            "style": "IPY_MODEL_ec5ca8de6a42450e8552ed2e655fc910",
            "value": " 25793/25793 [00:20&lt;00:00, 1573.61 examples/s]"
          }
        },
        "d079a34e9da44461a4f1df46768484e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d2c2ea3d1484dd5b93e81d3149aea62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9279a17743be47f3ae31ad2b927bfbee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f000d6c1e8b5499aa6e3b115db634da8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4126a513164462ba2bc19d2e5274e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "102853408df44ad7b85b88f6caf8fe93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec5ca8de6a42450e8552ed2e655fc910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d617feb6eb0444ea3ec868d618322b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95c7f304b0734a4fbed1df6ce1df3b25",
              "IPY_MODEL_04d89a2dc3764b99b2e9e3eecd096274",
              "IPY_MODEL_82cbfd349c0c4f5cbd6ae695d9daf1b4"
            ],
            "layout": "IPY_MODEL_4d941ce2ca6e4c4db02b40dbc1a330e9"
          }
        },
        "95c7f304b0734a4fbed1df6ce1df3b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f6ac4d7b56f41b8b32940c31a650fa3",
            "placeholder": "​",
            "style": "IPY_MODEL_ead119fcf090401c998fce4597f0b208",
            "value": "README.md: 100%"
          }
        },
        "04d89a2dc3764b99b2e9e3eecd096274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c8a0906b6734558aab7a0f9c2e6420e",
            "max": 579,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc1fa9ef712d4111aa2b805e1ba09db1",
            "value": 579
          }
        },
        "82cbfd349c0c4f5cbd6ae695d9daf1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ba5b857216149bd978d4cb445e334b0",
            "placeholder": "​",
            "style": "IPY_MODEL_4528786d3e074ddbae4b9e827e7fcef2",
            "value": " 579/579 [00:00&lt;00:00, 43.1kB/s]"
          }
        },
        "4d941ce2ca6e4c4db02b40dbc1a330e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f6ac4d7b56f41b8b32940c31a650fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ead119fcf090401c998fce4597f0b208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c8a0906b6734558aab7a0f9c2e6420e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc1fa9ef712d4111aa2b805e1ba09db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ba5b857216149bd978d4cb445e334b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4528786d3e074ddbae4b9e827e7fcef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24e176e1be3142ac8382645001b72b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac5d7847de1340cda3ad4bb4d22d0522",
              "IPY_MODEL_a65cc0b67ce8452c8317806025be2887",
              "IPY_MODEL_cd097f0da9284cb7bb9da1e906bb7b4b"
            ],
            "layout": "IPY_MODEL_8f1fc67c3b834854be2a54901e0916d2"
          }
        },
        "ac5d7847de1340cda3ad4bb4d22d0522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c6c8e8e87784254b9c7b3ed011cb188",
            "placeholder": "​",
            "style": "IPY_MODEL_b70c9f1911b64b3bba586359888dbde9",
            "value": "100%"
          }
        },
        "a65cc0b67ce8452c8317806025be2887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e53ece7e84443680080f32135f46cb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_438aafa8291845d1a4891e809fd57b4b",
            "value": 1
          }
        },
        "cd097f0da9284cb7bb9da1e906bb7b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9326dc3805f245098b11db121a088f7a",
            "placeholder": "​",
            "style": "IPY_MODEL_db162b2c5ec54b4fa333d3743e67a70e",
            "value": " 1/1 [00:01&lt;00:00,  1.92s/it]"
          }
        },
        "8f1fc67c3b834854be2a54901e0916d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c6c8e8e87784254b9c7b3ed011cb188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b70c9f1911b64b3bba586359888dbde9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2e53ece7e84443680080f32135f46cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "438aafa8291845d1a4891e809fd57b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9326dc3805f245098b11db121a088f7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db162b2c5ec54b4fa333d3743e67a70e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4ad3d31d8374cd982ad08bf201d3aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83d94e10cf8c44709dd3d5e4ade17049",
              "IPY_MODEL_e7cc1df618754b738e8793971a2143f5",
              "IPY_MODEL_e1770822e62a4a5491ccf55133680dd0"
            ],
            "layout": "IPY_MODEL_8f1a84664aeb4bc885f68d2450953c7f"
          }
        },
        "83d94e10cf8c44709dd3d5e4ade17049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e1cd86ca8b461aaa679b9248c6dae1",
            "placeholder": "​",
            "style": "IPY_MODEL_603419dceafc4beb92ede6fc6080e7a8",
            "value": "adapter_model.safetensors: "
          }
        },
        "e7cc1df618754b738e8793971a2143f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0bfd1744be24244a29abf1d0a9f88a5",
            "max": 159967880,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e46d31aaa69454b86ca56535de748df",
            "value": 159967880
          }
        },
        "e1770822e62a4a5491ccf55133680dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_674b4480208a4f4c8f92d0303700e11f",
            "placeholder": "​",
            "style": "IPY_MODEL_d2c80f468fd543b8842a78b63df75155",
            "value": " 160M/? [00:01&lt;00:00, 168MB/s]"
          }
        },
        "8f1a84664aeb4bc885f68d2450953c7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2e1cd86ca8b461aaa679b9248c6dae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "603419dceafc4beb92ede6fc6080e7a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0bfd1744be24244a29abf1d0a9f88a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e46d31aaa69454b86ca56535de748df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "674b4480208a4f4c8f92d0303700e11f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2c80f468fd543b8842a78b63df75155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b0dbda896aa4a53b8920234fb9c6aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44db06b16c01479fa42b709bd12e6363",
              "IPY_MODEL_14b34a0dd22740c48baa47e89a00714e",
              "IPY_MODEL_48c45ce269b74d4ca0805197e8750f0a"
            ],
            "layout": "IPY_MODEL_62b33dd91fab4b2fb80e970dd492554e"
          }
        },
        "44db06b16c01479fa42b709bd12e6363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6eee0a9ecca415cbd304329a6bbee56",
            "placeholder": "​",
            "style": "IPY_MODEL_b6bfc17a7da745908c8d2018d4bb363d",
            "value": "100%"
          }
        },
        "14b34a0dd22740c48baa47e89a00714e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72bdb584f9fc4c418f6b05f41c5b2dd7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_636850e116894d4c8447f6ba708c601f",
            "value": 1
          }
        },
        "48c45ce269b74d4ca0805197e8750f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b67abc0748434ae8a79c44c54c6fa4b9",
            "placeholder": "​",
            "style": "IPY_MODEL_13cc47a3e7f14cd98ff220ef3d8a46c7",
            "value": " 1/1 [00:36&lt;00:00, 36.69s/it]"
          }
        },
        "62b33dd91fab4b2fb80e970dd492554e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6eee0a9ecca415cbd304329a6bbee56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6bfc17a7da745908c8d2018d4bb363d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72bdb584f9fc4c418f6b05f41c5b2dd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "636850e116894d4c8447f6ba708c601f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b67abc0748434ae8a79c44c54c6fa4b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13cc47a3e7f14cd98ff220ef3d8a46c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "217c25a8d11e4ee88100a68741585d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8357ca43ff344217989b031116511035",
              "IPY_MODEL_6491230e5658495888cd0ed94e8a3eca",
              "IPY_MODEL_ceeb872d412c4af194267229816acbfb"
            ],
            "layout": "IPY_MODEL_2aee3dbd1ca44f3b8b998662bd0ccf5f"
          }
        },
        "8357ca43ff344217989b031116511035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_535b0069a9db4e81a4169fbcf045b029",
            "placeholder": "​",
            "style": "IPY_MODEL_280d48e7c55546fdb3ca257e757abe08",
            "value": "unsloth.Q4_K_M.gguf: "
          }
        },
        "6491230e5658495888cd0ed94e8a3eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ad052e4c73448b7a0a6b08e207770ab",
            "max": 4081095904,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78e76b55708b49c999177117eaf30173",
            "value": 4081095904
          }
        },
        "ceeb872d412c4af194267229816acbfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38f77572a0274a49aa547d77a8468c26",
            "placeholder": "​",
            "style": "IPY_MODEL_496268b65ad14ed8b1813dddbb50b3d9",
            "value": " 4.10G/? [00:36&lt;00:00, 516MB/s]"
          }
        },
        "2aee3dbd1ca44f3b8b998662bd0ccf5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "535b0069a9db4e81a4169fbcf045b029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "280d48e7c55546fdb3ca257e757abe08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ad052e4c73448b7a0a6b08e207770ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78e76b55708b49c999177117eaf30173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38f77572a0274a49aa547d77a8468c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "496268b65ad14ed8b1813dddbb50b3d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa9c960f8cb94053a1d9d9d96dd8caec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba22d0009add46309b15b98e74b804af",
              "IPY_MODEL_76b034def6e542aabf21afc18ec50614",
              "IPY_MODEL_81282b7cb54d45aeaf98b41699674aa8"
            ],
            "layout": "IPY_MODEL_de69dc91c0254bc68ecdaa30dcabdb83"
          }
        },
        "ba22d0009add46309b15b98e74b804af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d9b1dedfe114b0aaa502cccb5ebe2cc",
            "placeholder": "​",
            "style": "IPY_MODEL_0a92ddbb6d764b5b9b0e0cb3f2d7de17",
            "value": "100%"
          }
        },
        "76b034def6e542aabf21afc18ec50614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d3b6728564346edb962907ab872c764",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_806eec90b0d54ff7bb6a5a9facd5cd78",
            "value": 1
          }
        },
        "81282b7cb54d45aeaf98b41699674aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_975f653e4a7048d3b74bc3bcff5534ae",
            "placeholder": "​",
            "style": "IPY_MODEL_390629d366d64cd3a9408364d0912c94",
            "value": " 1/1 [01:02&lt;00:00, 62.66s/it]"
          }
        },
        "de69dc91c0254bc68ecdaa30dcabdb83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d9b1dedfe114b0aaa502cccb5ebe2cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a92ddbb6d764b5b9b0e0cb3f2d7de17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d3b6728564346edb962907ab872c764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "806eec90b0d54ff7bb6a5a9facd5cd78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "975f653e4a7048d3b74bc3bcff5534ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390629d366d64cd3a9408364d0912c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf966c4722c94113a91fe46e2ab46efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd97258189144ed3803677fa6e6e17ae",
              "IPY_MODEL_e1fd562d5dec4634b392ebdc3952371c",
              "IPY_MODEL_3eb65a2d49794020939eece5c78cd84c"
            ],
            "layout": "IPY_MODEL_218e094db2ea48aaa2293dda9c3f22d8"
          }
        },
        "cd97258189144ed3803677fa6e6e17ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0901823f4dac48dc9351b9e0d6a5e2e4",
            "placeholder": "​",
            "style": "IPY_MODEL_c6305c6b700f411a880cb54e8fe83947",
            "value": "unsloth.Q8_0.gguf: "
          }
        },
        "e1fd562d5dec4634b392ebdc3952371c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8b7cf380c244da5997d38e60cd20b24",
            "max": 7161230048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7d4b017fe094855a8bc1f1e8c450fbd",
            "value": 7161230048
          }
        },
        "3eb65a2d49794020939eece5c78cd84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bb6aa6bf34a43bd8aca98c6b93a8f71",
            "placeholder": "​",
            "style": "IPY_MODEL_412e9140c6aa459da0e8181dd713afe1",
            "value": " 7.17G/? [01:02&lt;00:00, 830MB/s]"
          }
        },
        "218e094db2ea48aaa2293dda9c3f22d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0901823f4dac48dc9351b9e0d6a5e2e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6305c6b700f411a880cb54e8fe83947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8b7cf380c244da5997d38e60cd20b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7d4b017fe094855a8bc1f1e8c450fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bb6aa6bf34a43bd8aca98c6b93a8f71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "412e9140c6aa459da0e8181dd713afe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9da1aad051d40f8b77080a1c4554d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f34e975ef584236a83ee24fd9559477",
              "IPY_MODEL_5bb6fcb397914e2d952f3d2a75b038b2",
              "IPY_MODEL_9917d19a55864a42b9569f238a88ca4a"
            ],
            "layout": "IPY_MODEL_7c1eeefed7bf4f08a3993c6666762f96"
          }
        },
        "1f34e975ef584236a83ee24fd9559477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_459a8628d4f9410ca6f8ae6ad8b140ec",
            "placeholder": "​",
            "style": "IPY_MODEL_73cdacd2d62f44c99906849bb94fa475",
            "value": "100%"
          }
        },
        "5bb6fcb397914e2d952f3d2a75b038b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_167542bbe45546d88a614880f76274ca",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcd42f789bd34042b3dd7ab2c41587b2",
            "value": 1
          }
        },
        "9917d19a55864a42b9569f238a88ca4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5fb7ac997ed444ebef2eea593fa0b1f",
            "placeholder": "​",
            "style": "IPY_MODEL_367b1c2ef6f8464789353db67fad4421",
            "value": " 1/1 [00:42&lt;00:00, 42.08s/it]"
          }
        },
        "7c1eeefed7bf4f08a3993c6666762f96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "459a8628d4f9410ca6f8ae6ad8b140ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73cdacd2d62f44c99906849bb94fa475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "167542bbe45546d88a614880f76274ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcd42f789bd34042b3dd7ab2c41587b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5fb7ac997ed444ebef2eea593fa0b1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "367b1c2ef6f8464789353db67fad4421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a0172801a40413ab37f68ddb7539ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a8f0eb1fd43455da13d534378db6546",
              "IPY_MODEL_b5eb3a68315f4868a5f1f1ccc93ebc3c",
              "IPY_MODEL_4d79bcbb000e409d99516a908477c56c"
            ],
            "layout": "IPY_MODEL_863273c5a9984cc4a479aa32946b2817"
          }
        },
        "4a8f0eb1fd43455da13d534378db6546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5605493b02ec44b28e6b9ab6d62fd0d7",
            "placeholder": "​",
            "style": "IPY_MODEL_8d3a359c1c1d4d0ba7ab2356fc908664",
            "value": "unsloth.Q5_K_M.gguf: "
          }
        },
        "b5eb3a68315f4868a5f1f1ccc93ebc3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_138acd3764ce417bac669d1d0bccbd0a",
            "max": 4783256800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5648fa19d3aa48959559d8e54bf37424",
            "value": 4783256800
          }
        },
        "4d79bcbb000e409d99516a908477c56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b057f6d99cb4685bb3c8141164eaa25",
            "placeholder": "​",
            "style": "IPY_MODEL_c6044df5fd6147b9a028f8e08f01efef",
            "value": " 4.78G/? [00:41&lt;00:00, 609MB/s]"
          }
        },
        "863273c5a9984cc4a479aa32946b2817": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5605493b02ec44b28e6b9ab6d62fd0d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d3a359c1c1d4d0ba7ab2356fc908664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "138acd3764ce417bac669d1d0bccbd0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5648fa19d3aa48959559d8e54bf37424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b057f6d99cb4685bb3c8141164eaa25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6044df5fd6147b9a028f8e08f01efef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "363c1c2c7ada417c9db5540d92fb61d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4acbab3d1cec4044a4f5a7cc9f0a2886",
              "IPY_MODEL_b379c5e5cd4e40e0b59dd5c0715a00d5",
              "IPY_MODEL_f0b0d31a0143460993d718b42b61d7db"
            ],
            "layout": "IPY_MODEL_07e54f526c6f4d85a40f02e0e934eb09"
          }
        },
        "4acbab3d1cec4044a4f5a7cc9f0a2886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ed9e4e124964a15ad53d1b3e6ef9876",
            "placeholder": "​",
            "style": "IPY_MODEL_fb024c345f50429f9c412527f16f94a0",
            "value": "model.safetensors: 100%"
          }
        },
        "b379c5e5cd4e40e0b59dd5c0715a00d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6d7c14587e741b19c5bc686fdcd11e4",
            "max": 3866304467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b09b685f36c44bbb9976e1ca3b4f6cf7",
            "value": 3866304099
          }
        },
        "f0b0d31a0143460993d718b42b61d7db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd416caad881447c98012c15d3d42ada",
            "placeholder": "​",
            "style": "IPY_MODEL_8a9f78f7cff547d8968eea8c80f354da",
            "value": " 3.87G/3.87G [00:28&lt;00:00, 468MB/s]"
          }
        },
        "07e54f526c6f4d85a40f02e0e934eb09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ed9e4e124964a15ad53d1b3e6ef9876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb024c345f50429f9c412527f16f94a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6d7c14587e741b19c5bc686fdcd11e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b09b685f36c44bbb9976e1ca3b4f6cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd416caad881447c98012c15d3d42ada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a9f78f7cff547d8968eea8c80f354da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "386a98c9703d4f1aa092e9ef8195fcb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03f3c08c9a01474aa21c60ec37f80c84",
              "IPY_MODEL_d3f998d1dbdc465a8635bcde43e893da",
              "IPY_MODEL_5792f730d1044ac08d3c6f18917a644b"
            ],
            "layout": "IPY_MODEL_563d8ea20af34ce6ad7189d4a76d3ca1"
          }
        },
        "03f3c08c9a01474aa21c60ec37f80c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44b11d1440084394926ebb64c9ccc457",
            "placeholder": "​",
            "style": "IPY_MODEL_fa1c1bd7f4ff47cd98627e86c0d094e7",
            "value": "generation_config.json: 100%"
          }
        },
        "d3f998d1dbdc465a8635bcde43e893da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a23fb44d7afd4d34b79a5802f0a43c6f",
            "max": 155,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c396b553717c45dc8e017441a0aae334",
            "value": 155
          }
        },
        "5792f730d1044ac08d3c6f18917a644b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4bc8e3e1a24499eb0aa8c22b1f04173",
            "placeholder": "​",
            "style": "IPY_MODEL_a52c7301439948d08d7faa746ead9ab9",
            "value": " 155/155 [00:00&lt;00:00, 15.1kB/s]"
          }
        },
        "563d8ea20af34ce6ad7189d4a76d3ca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44b11d1440084394926ebb64c9ccc457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa1c1bd7f4ff47cd98627e86c0d094e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a23fb44d7afd4d34b79a5802f0a43c6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c396b553717c45dc8e017441a0aae334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4bc8e3e1a24499eb0aa8c22b1f04173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a52c7301439948d08d7faa746ead9ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b612d91eb4864cef9b80c8d9dcea286f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b71e08a7b074b91aefb529cb6f85c75",
              "IPY_MODEL_3cae308426b644bf82bb584c850ece37",
              "IPY_MODEL_c210f7ff399e4b30ae2ff54846f4871f"
            ],
            "layout": "IPY_MODEL_5e103635ba1740c4a55e3fbd3022d58b"
          }
        },
        "7b71e08a7b074b91aefb529cb6f85c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e42702fbcbab4108a1fd0dd8f5be50ac",
            "placeholder": "​",
            "style": "IPY_MODEL_aeee0e52502a4040ab6e54cb2d36fbf5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3cae308426b644bf82bb584c850ece37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_069441c89b4b4f798aa141060cd20b60",
            "max": 1866,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a561f88994a84216ace9ce4b69dcce99",
            "value": 1866
          }
        },
        "c210f7ff399e4b30ae2ff54846f4871f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70a6bc7c3966445b813f09df123c5880",
            "placeholder": "​",
            "style": "IPY_MODEL_c2987af414b1494f88c2774a908f444b",
            "value": " 1.87k/1.87k [00:00&lt;00:00, 208kB/s]"
          }
        },
        "5e103635ba1740c4a55e3fbd3022d58b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e42702fbcbab4108a1fd0dd8f5be50ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeee0e52502a4040ab6e54cb2d36fbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "069441c89b4b4f798aa141060cd20b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a561f88994a84216ace9ce4b69dcce99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70a6bc7c3966445b813f09df123c5880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2987af414b1494f88c2774a908f444b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f9f7e40088944d8aaf63f029b95930d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b007590a8d144048aafc8fa67fba2668",
              "IPY_MODEL_a1d4896b76e045cd8258c000b9ae50e8",
              "IPY_MODEL_3f30e87070304b7697501e6734401650"
            ],
            "layout": "IPY_MODEL_4430565886b34ee49d792d6369bc5b87"
          }
        },
        "b007590a8d144048aafc8fa67fba2668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_936ca9a37f2a4c78acdad4916e033a7c",
            "placeholder": "​",
            "style": "IPY_MODEL_02f003f02ef94ea28b9d090d626b2646",
            "value": "tokenizer.model: 100%"
          }
        },
        "a1d4896b76e045cd8258c000b9ae50e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_508a3eaaf02c49c9be3570f0c1f7bfcc",
            "max": 500058,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab025b1f4e974cc0855c8e5d76cadc56",
            "value": 500058
          }
        },
        "3f30e87070304b7697501e6734401650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b51dde106ae43ac856d83a3cb837891",
            "placeholder": "​",
            "style": "IPY_MODEL_ce81b4263d584982965e2fd8ccdd663d",
            "value": " 500k/500k [00:00&lt;00:00, 8.28MB/s]"
          }
        },
        "4430565886b34ee49d792d6369bc5b87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "936ca9a37f2a4c78acdad4916e033a7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02f003f02ef94ea28b9d090d626b2646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "508a3eaaf02c49c9be3570f0c1f7bfcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab025b1f4e974cc0855c8e5d76cadc56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b51dde106ae43ac856d83a3cb837891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce81b4263d584982965e2fd8ccdd663d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dc4489ae08f4ce19686f405dbfec06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b81b8941b8c4bc3a834024029dc81f9",
              "IPY_MODEL_47a07d8a609e45fa953d4ae2ae24ca2f",
              "IPY_MODEL_615ba0104ed34c5396d9f61a2900b8e1"
            ],
            "layout": "IPY_MODEL_8644afc0a7564f25bb7f80f2d450e7c7"
          }
        },
        "0b81b8941b8c4bc3a834024029dc81f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be397d71ad784d239db815ae5351f7c4",
            "placeholder": "​",
            "style": "IPY_MODEL_a1f3f7265dfd47749930b2e8cd50a089",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "47a07d8a609e45fa953d4ae2ae24ca2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb182b387daa409cae0c75063a8b4d70",
            "max": 539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2418c5f8c3504ea49bb7e7dd9d94bf1f",
            "value": 539
          }
        },
        "615ba0104ed34c5396d9f61a2900b8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4266c530f1ec44c0b1ab07755d4b1354",
            "placeholder": "​",
            "style": "IPY_MODEL_866fad7d2a344b3393691d9ebfca9a48",
            "value": " 539/539 [00:00&lt;00:00, 59.1kB/s]"
          }
        },
        "8644afc0a7564f25bb7f80f2d450e7c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be397d71ad784d239db815ae5351f7c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f3f7265dfd47749930b2e8cd50a089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb182b387daa409cae0c75063a8b4d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2418c5f8c3504ea49bb7e7dd9d94bf1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4266c530f1ec44c0b1ab07755d4b1354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "866fad7d2a344b3393691d9ebfca9a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14ef8f86bbcd4d35a2fa10127db44dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3679d5b4bdd42d9a3a6b96842f7e77a",
              "IPY_MODEL_8b6ea047cc984d7a91409744a411e14c",
              "IPY_MODEL_b5b12fc7e79f4f4ea3ad433ec02261c9"
            ],
            "layout": "IPY_MODEL_05c7672ef54c4d3cbe9761fdae23665d"
          }
        },
        "c3679d5b4bdd42d9a3a6b96842f7e77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4edc254403a5421b9773005398a7b4c9",
            "placeholder": "​",
            "style": "IPY_MODEL_7d25f7591e8a4aafa2983e8661f5924c",
            "value": "tokenizer.json: 100%"
          }
        },
        "8b6ea047cc984d7a91409744a411e14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7d2d8671075495d9dfd07585ea73591",
            "max": 1844191,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0973d3bc9bb450b8df54393ff673341",
            "value": 1844191
          }
        },
        "b5b12fc7e79f4f4ea3ad433ec02261c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfa10d1c636f4b8f85d7cce531f9609b",
            "placeholder": "​",
            "style": "IPY_MODEL_d478dac05f924373916c8ec92896dd7c",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 5.64MB/s]"
          }
        },
        "05c7672ef54c4d3cbe9761fdae23665d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4edc254403a5421b9773005398a7b4c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d25f7591e8a4aafa2983e8661f5924c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7d2d8671075495d9dfd07585ea73591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0973d3bc9bb450b8df54393ff673341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfa10d1c636f4b8f85d7cce531f9609b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d478dac05f924373916c8ec92896dd7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s5f8yBxQ4NwX"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth \"xformers==0.0.28.post2\"\n",
        "# Also get the latest nightly Unsloth!\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048\n",
        "dtype = None # None for auto detection.\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage.\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained( model_name = \"unsloth/codellama-7b-bnb-4bit\", max_seq_length = max_seq_length, dtype = dtype, load_in_4bit = load_in_4bit, )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365,
          "referenced_widgets": [
            "363c1c2c7ada417c9db5540d92fb61d1",
            "4acbab3d1cec4044a4f5a7cc9f0a2886",
            "b379c5e5cd4e40e0b59dd5c0715a00d5",
            "f0b0d31a0143460993d718b42b61d7db",
            "07e54f526c6f4d85a40f02e0e934eb09",
            "0ed9e4e124964a15ad53d1b3e6ef9876",
            "fb024c345f50429f9c412527f16f94a0",
            "f6d7c14587e741b19c5bc686fdcd11e4",
            "b09b685f36c44bbb9976e1ca3b4f6cf7",
            "bd416caad881447c98012c15d3d42ada",
            "8a9f78f7cff547d8968eea8c80f354da",
            "386a98c9703d4f1aa092e9ef8195fcb3",
            "03f3c08c9a01474aa21c60ec37f80c84",
            "d3f998d1dbdc465a8635bcde43e893da",
            "5792f730d1044ac08d3c6f18917a644b",
            "563d8ea20af34ce6ad7189d4a76d3ca1",
            "44b11d1440084394926ebb64c9ccc457",
            "fa1c1bd7f4ff47cd98627e86c0d094e7",
            "a23fb44d7afd4d34b79a5802f0a43c6f",
            "c396b553717c45dc8e017441a0aae334",
            "c4bc8e3e1a24499eb0aa8c22b1f04173",
            "a52c7301439948d08d7faa746ead9ab9",
            "b612d91eb4864cef9b80c8d9dcea286f",
            "7b71e08a7b074b91aefb529cb6f85c75",
            "3cae308426b644bf82bb584c850ece37",
            "c210f7ff399e4b30ae2ff54846f4871f",
            "5e103635ba1740c4a55e3fbd3022d58b",
            "e42702fbcbab4108a1fd0dd8f5be50ac",
            "aeee0e52502a4040ab6e54cb2d36fbf5",
            "069441c89b4b4f798aa141060cd20b60",
            "a561f88994a84216ace9ce4b69dcce99",
            "70a6bc7c3966445b813f09df123c5880",
            "c2987af414b1494f88c2774a908f444b",
            "8f9f7e40088944d8aaf63f029b95930d",
            "b007590a8d144048aafc8fa67fba2668",
            "a1d4896b76e045cd8258c000b9ae50e8",
            "3f30e87070304b7697501e6734401650",
            "4430565886b34ee49d792d6369bc5b87",
            "936ca9a37f2a4c78acdad4916e033a7c",
            "02f003f02ef94ea28b9d090d626b2646",
            "508a3eaaf02c49c9be3570f0c1f7bfcc",
            "ab025b1f4e974cc0855c8e5d76cadc56",
            "7b51dde106ae43ac856d83a3cb837891",
            "ce81b4263d584982965e2fd8ccdd663d",
            "9dc4489ae08f4ce19686f405dbfec06e",
            "0b81b8941b8c4bc3a834024029dc81f9",
            "47a07d8a609e45fa953d4ae2ae24ca2f",
            "615ba0104ed34c5396d9f61a2900b8e1",
            "8644afc0a7564f25bb7f80f2d450e7c7",
            "be397d71ad784d239db815ae5351f7c4",
            "a1f3f7265dfd47749930b2e8cd50a089",
            "bb182b387daa409cae0c75063a8b4d70",
            "2418c5f8c3504ea49bb7e7dd9d94bf1f",
            "4266c530f1ec44c0b1ab07755d4b1354",
            "866fad7d2a344b3393691d9ebfca9a48",
            "14ef8f86bbcd4d35a2fa10127db44dd7",
            "c3679d5b4bdd42d9a3a6b96842f7e77a",
            "8b6ea047cc984d7a91409744a411e14c",
            "b5b12fc7e79f4f4ea3ad433ec02261c9",
            "05c7672ef54c4d3cbe9761fdae23665d",
            "4edc254403a5421b9773005398a7b4c9",
            "7d25f7591e8a4aafa2983e8661f5924c",
            "d7d2d8671075495d9dfd07585ea73591",
            "a0973d3bc9bb450b8df54393ff673341",
            "bfa10d1c636f4b8f85d7cce531f9609b",
            "d478dac05f924373916c8ec92896dd7c"
          ]
        },
        "id": "3X2tTh-tHeOt",
        "outputId": "85503d13-ba73-49f2-c0c1-e27752015065"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Patching Xformers to fix some performance issues.\n",
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.0.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.87G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "363c1c2c7ada417c9db5540d92fb61d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/155 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "386a98c9703d4f1aa092e9ef8195fcb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.87k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b612d91eb4864cef9b80c8d9dcea286f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f9f7e40088944d8aaf63f029b95930d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/539 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9dc4489ae08f4ce19686f405dbfec06e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14ef8f86bbcd4d35a2fa10127db44dd7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "HmLVRCdK_jxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f2104f-2551-42b1-8f01-a9520caf12c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the LoRA technique on our model for fine-tuning\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, #  > 0 like 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # 0 is optimized\n",
        "    bias = \"none\",    # \"none\" is optimized\n",
        "    use_gradient_checkpointing = \"unsloth\", # \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ],
      "metadata": {
        "id": "6MUrDEsH_zot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "401d2443-bc6e-47f5-98bd-f4ed8d82865c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.3.15 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install datasets transformers evaluate tqdm matplotlib seaborn pandas numpy torch ollama\n",
        "# Reading the Dataset from Hugging Face\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"Krish-05/krish-bug-detect-fix\", split=\"train\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "RABrrUaMAAiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e87aa8-2d66-4db6-eb80-0a59456fb314"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: ollama in /usr/local/lib/python3.11/dist-packages (0.4.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from ollama) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from ollama) (2.10.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['original_code', 'modified_code', 'changed_line', 'number_of_line', 'mutation_type'],\n",
              "    num_rows: 25793\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up a template prompt and using a function to tokenizing the input.\n",
        "# Our Input of the fuction is one row of our dataset.\n",
        "# We use just modified_code and original_code columns. Putting modified_code detail in the Input and original_code in the Response.\n",
        "# We are using the best prompt for instruction.\n",
        "\n",
        "alpaca_prompt = \"\"\"The following code contains a bug. First, analyze the code and add comments explaining it. Then, identify the bug, fix it, and finally remove the comments. Please do this without any further explanation:\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    inputs       = examples[\"modified_code\"]\n",
        "    outputs      = examples[\"original_code\"]\n",
        "    texts = []\n",
        "    for input, output in zip(inputs, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = alpaca_prompt.format(input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
        "dataset"
      ],
      "metadata": {
        "id": "ahZjAfylALL-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "4c3b960b475044958b449b9bc32d1371",
            "4ad8b1994f5b4481b3d7531896e7e23f",
            "8e989afbb14e4d6ea3c1368449e0cc1c",
            "e4a6c8260d1e44b1945aa3a4ae0ab201",
            "f8b37b12e16143ea813475fbaf9d7186",
            "2a775a65ac5a48b7bb5994039b33e338",
            "016c5739d41a47d3a14ddbbcba919f57",
            "bdd48c9cf55c431aada1efeb07d1530b",
            "5ddc35a990034996aaec4e2610bf950c",
            "e3c58daa7ad24314adb0e2f69f226c34",
            "7d5836138943463eaec2d05ca48e21c8"
          ]
        },
        "outputId": "2dec0e8f-801a-4cfb-c38b-808fe935d91b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25793 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c3b960b475044958b449b9bc32d1371"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['original_code', 'modified_code', 'changed_line', 'number_of_line', 'mutation_type', 'text'],\n",
              "    num_rows: 25793\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "id": "5jJSgKFWAQ0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4eb044-616d-425a-d179-a081890f0f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'original_code': 'n = int(input())\\nw = [2] * n\\nans0 = n\\nans = []\\nq = int(input())\\nfor i in range(q):\\n    l, r, k = list(map(int, input().split()))\\n    if k == 1:\\n        for j in range(l-1, r):\\n            if w[j] == 2:\\n                ans0 -= 1\\n                w[j] = 1\\n    else:\\n        for j in range(l-1, r):\\n            if w[j] == 1:\\n                ans0 += 1\\n                w[j] = 2\\n    ans.append(ans0)\\nfor i in range(q):\\n    print(ans[i])', 'modified_code': 'n = int(input())\\nw = [2] * n\\nans0 = n\\nans = []\\nq = int(input())\\nfor i in range(q):\\n    l, r, k = list(map(int, input().split()))\\n    if k == 1:\\n        for j in range(l-1, r):\\n            if w[j] == 2:\\n                ans0 -= 1\\n                w[j] = 1\\n    else:\\n        for j in range(y-1, r):\\n            if w[j] == 1:\\n                ans0 += 1\\n                w[j] = 2\\n    ans.append(ans0)\\nfor i in range(q):\\n    print(ans[i])', 'changed_line': '        for j in range(y-1, r):', 'number_of_line': 14, 'mutation_type': 'statement', 'text': 'The following code contains a bug. First, analyze the code and add comments explaining it. Then, identify the bug, fix it, and finally remove the comments. Please do this without any further explanation:\\n\\n### Input:\\nn = int(input())\\nw = [2] * n\\nans0 = n\\nans = []\\nq = int(input())\\nfor i in range(q):\\n    l, r, k = list(map(int, input().split()))\\n    if k == 1:\\n        for j in range(l-1, r):\\n            if w[j] == 2:\\n                ans0 -= 1\\n                w[j] = 1\\n    else:\\n        for j in range(y-1, r):\\n            if w[j] == 1:\\n                ans0 += 1\\n                w[j] = 2\\n    ans.append(ans0)\\nfor i in range(q):\\n    print(ans[i])\\n\\n### Response:\\nn = int(input())\\nw = [2] * n\\nans0 = n\\nans = []\\nq = int(input())\\nfor i in range(q):\\n    l, r, k = list(map(int, input().split()))\\n    if k == 1:\\n        for j in range(l-1, r):\\n            if w[j] == 2:\\n                ans0 -= 1\\n                w[j] = 1\\n    else:\\n        for j in range(l-1, r):\\n            if w[j] == 1:\\n                ans0 += 1\\n                w[j] = 2\\n    ans.append(ans0)\\nfor i in range(q):\\n    print(ans[i])</s>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**"
      ],
      "metadata": {
        "id": "woy6PJpoAVcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the attributes of training our model\n",
        "\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 100,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        save_strategy=\"epoch\",  # Save model after each epoch (optional)\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "TKGfOW8QATCB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c9f1744b59f440c68ffa9c3ebd1c6254",
            "314719aad6794ddcba4020ee3c6554f6",
            "44383b076f254e0dac7c52f1091a3fc9",
            "1a4530fb1876459a91be91b25c407e82",
            "d079a34e9da44461a4f1df46768484e8",
            "2d2c2ea3d1484dd5b93e81d3149aea62",
            "9279a17743be47f3ae31ad2b927bfbee",
            "f000d6c1e8b5499aa6e3b115db634da8",
            "7b4126a513164462ba2bc19d2e5274e7",
            "102853408df44ad7b85b88f6caf8fe93",
            "ec5ca8de6a42450e8552ed2e655fc910"
          ]
        },
        "outputId": "18319f7e-b655-4ac9-eab5-2030f27181c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/25793 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9f1744b59f440c68ffa9c3ebd1c6254"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ],
      "metadata": {
        "id": "3JuRsRruAkQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c632048-3198-4970-dbcf-cd2fbeefd38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "3.762 GB of memory reserved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "id": "-p2YleYwAmXD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f108cb0-a46f-45cb-a8cf-720be2ee4665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 25,793 | Num Epochs = 1 | Total steps = 100\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 39,976,960/7,000,000,000 (0.57% trained)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msec22cj052\u001b[0m (\u001b[33msec22cj052-sri-sairam-engineering-college\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250318_162541-75eusior</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sec22cj052-sri-sairam-engineering-college/huggingface/runs/75eusior' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/sec22cj052-sri-sairam-engineering-college/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sec22cj052-sri-sairam-engineering-college/huggingface' target=\"_blank\">https://wandb.ai/sec22cj052-sri-sairam-engineering-college/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sec22cj052-sri-sairam-engineering-college/huggingface/runs/75eusior' target=\"_blank\">https://wandb.ai/sec22cj052-sri-sairam-engineering-college/huggingface/runs/75eusior</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 18:09, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.764900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.700900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.821700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.776400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.712800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.705200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.714000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.564900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.484300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.481900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.517900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.417500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.440600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.352600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.393800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.410900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.375200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.386000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.431800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.380300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.380700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.361200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.428200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.337900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.416200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.372500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.369700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.351600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.373400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.390900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.338300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.381100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.392600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.456100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.378300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.326200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.369600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.578100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.357300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.351900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.289000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.389900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.347400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.341000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.332800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.393800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.354500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.339100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.367100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.354600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.337300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.365200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.307900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.337400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.343900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.337800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.324600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.350100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.344400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.307200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.329900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.341500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.409600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.326500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.364200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.344200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.355800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.398600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.289300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.325600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.408500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.378800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.311500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.411800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.443000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.337300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.352100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.377200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.358100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.341600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.341900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.302100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.330700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.381300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.374500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.348000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.323500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.353500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.341000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.348600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.298900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.341500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.366200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.377100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.351600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.393100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.376500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training loss of our training.\n",
        "# Also, we can visit other plots on https://wandb.me/wandb-core\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "log_history = trainer.state.log_history\n",
        "\n",
        "# Initialize lists for loss, accuracy, and steps\n",
        "losses = []\n",
        "steps = []\n",
        "\n",
        "# Collect data for plotting (loss)\n",
        "for log in log_history:\n",
        "    if 'loss' in log:\n",
        "        losses.append(log['loss'])\n",
        "        steps.append(log['step'])\n",
        "\n",
        "# Plotting loss\n",
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plotting loss\n",
        "ax1.set_xlabel('Steps')\n",
        "ax1.set_ylabel('Loss', color='tab:blue')\n",
        "ax1.plot(steps, losses, label='Loss', color='tab:blue')\n",
        "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
        "\n",
        "fig.tight_layout()  # To make sure the labels don't overlap\n",
        "plt.title('Training Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cmhIw7VcGgJe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "16b72f64-5526-45b1-8eb7-791db3740bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After fine tuning Model"
      ],
      "metadata": {
        "id": "a4fCOwkcGw8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"The following code contains a bug. First, analyze the code and add comments explaining it. Then, identify the bug, fix it, and finally remove the comments. Please do this without any further explanation\",\n",
        "        dataset[0][\"modified_code\"], # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
      ],
      "metadata": {
        "id": "saqniIKMGnOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c63f7d2-4a33-4d72-9f43-e54f25812823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> The following code contains a bug. First, analyze the code and add comments explaining it. Then, identify the bug, fix it, and finally remove the comments. Please do this without any further explanation:\n",
            "\n",
            "### Input:\n",
            "The following code contains a bug. First, analyze the code and add comments explaining it. Then, identify the bug, fix it, and finally remove the comments. Please do this without any further explanation\n",
            "\n",
            "### Response:\n",
            "n = int(input())\n",
            "w = [2] * n\n",
            "ans0 = n\n",
            "ans = []\n",
            "q = int(input())\n",
            "for i in range(q):\n",
            "    l, r, k = list(map(int, input().split()))\n",
            "    if k == 1:\n",
            "        for j in range(l-1, r):\n",
            "            if w[j] == 2:\n",
            "                ans0 -= 1\n",
            "                w[j] = 1\n",
            "    else:\n",
            "        for j in range(y-1, r):\n",
            "            if w[j] == 1:\n",
            "                ans0 += 1\n",
            "                w[j] = 2\n",
            "    ans.append(ans0)\n",
            "for i in range(q):\n",
            "    print(ans[i])\n",
            "\n",
            "### Response:\n",
            "The following code contains a bug. First, analyze the code and add comments explaining it. Then, identify the bug, fix it, and finally remove the comments. Please do this without any further explanation:\n",
            "\n",
            "### Response:\n",
            "The following code contains a bug. First, analyze the code and add comments explaining it. Then, identify the bug, fix it, and finally remove the comments. Please do this without any further explanation:\n",
            "\n",
            "### Response:\n",
            "The following code contains a bug. First, analyze the code and add comments explaining it. Then, identify the bug, fix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "upload on hugging face\n"
      ],
      "metadata": {
        "id": "K6rmcYVQHBZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving our Fine-Tuned model localy\n",
        "\n",
        "model.save_pretrained(\"codellama_fine_model\") # Local saving\n",
        "tokenizer.save_pretrained(\"codellama_fine_model\")"
      ],
      "metadata": {
        "id": "HfyfQi1-G9Gz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b67dd8-cf08-424c-a634-37921a3f22e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('codellama_fine_model/tokenizer_config.json',\n",
              " 'codellama_fine_model/special_tokens_map.json',\n",
              " 'codellama_fine_model/tokenizer.model',\n",
              " 'codellama_fine_model/added_tokens.json',\n",
              " 'codellama_fine_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the Fine-Tuned model on Hugging Face account\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(\"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\")\n",
        "\n",
        "model.push_to_hub(\"krishna-choudhary-codellama-Fine-tuned-model-bug-detection-fixing\") # Online saving\n",
        "tokenizer.push_to_hub(\"krishna-choudhary-codellama-Fine-tuned-model-bug-detection-fixing\") # Online saving"
      ],
      "metadata": {
        "id": "MW508EJIHPa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "2d617feb6eb0444ea3ec868d618322b4",
            "95c7f304b0734a4fbed1df6ce1df3b25",
            "04d89a2dc3764b99b2e9e3eecd096274",
            "82cbfd349c0c4f5cbd6ae695d9daf1b4",
            "4d941ce2ca6e4c4db02b40dbc1a330e9",
            "9f6ac4d7b56f41b8b32940c31a650fa3",
            "ead119fcf090401c998fce4597f0b208",
            "6c8a0906b6734558aab7a0f9c2e6420e",
            "cc1fa9ef712d4111aa2b805e1ba09db1",
            "6ba5b857216149bd978d4cb445e334b0",
            "4528786d3e074ddbae4b9e827e7fcef2",
            "24e176e1be3142ac8382645001b72b34",
            "ac5d7847de1340cda3ad4bb4d22d0522",
            "a65cc0b67ce8452c8317806025be2887",
            "cd097f0da9284cb7bb9da1e906bb7b4b",
            "8f1fc67c3b834854be2a54901e0916d2",
            "5c6c8e8e87784254b9c7b3ed011cb188",
            "b70c9f1911b64b3bba586359888dbde9",
            "c2e53ece7e84443680080f32135f46cb",
            "438aafa8291845d1a4891e809fd57b4b",
            "9326dc3805f245098b11db121a088f7a",
            "db162b2c5ec54b4fa333d3743e67a70e",
            "f4ad3d31d8374cd982ad08bf201d3aec",
            "83d94e10cf8c44709dd3d5e4ade17049",
            "e7cc1df618754b738e8793971a2143f5",
            "e1770822e62a4a5491ccf55133680dd0",
            "8f1a84664aeb4bc885f68d2450953c7f",
            "c2e1cd86ca8b461aaa679b9248c6dae1",
            "603419dceafc4beb92ede6fc6080e7a8",
            "e0bfd1744be24244a29abf1d0a9f88a5",
            "8e46d31aaa69454b86ca56535de748df",
            "674b4480208a4f4c8f92d0303700e11f",
            "d2c80f468fd543b8842a78b63df75155"
          ]
        },
        "outputId": "fa9f965e-504d-4248-d164-62129b36c8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/579 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d617feb6eb0444ea3ec868d618322b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24e176e1be3142ac8382645001b72b34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/160M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4ad3d31d8374cd982ad08bf201d3aec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to https://huggingface.co/krishna-choudhary-codellama-Fine-tuned-model-bug-detection-fixing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting model into GGUF format"
      ],
      "metadata": {
        "id": "UBUT0roxLY5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import os\n",
        "\n",
        "# Load your fine-tuned model\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Krish-05/krishna-choudhary-codellama-Fine-tuned-model-bug-detection-fixing\",\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        "    load_in_4bit = True,\n",
        ")\n",
        "\n",
        "# Set model to inference mode\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Your HuggingFace token\n",
        "token = \"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\"  # Replace with your actual token\n",
        "\n",
        "# Push the model to HuggingFace Hub with GGUF quantization\n",
        "model.push_to_hub_gguf(\n",
        "    \"Krish-05/krishna-choudhary-codellama-gguf-quantized\",  # Change to your desired repo name\n",
        "    tokenizer,\n",
        "    quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\"],\n",
        "    token = token,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2b0dbda896aa4a53b8920234fb9c6aea",
            "44db06b16c01479fa42b709bd12e6363",
            "14b34a0dd22740c48baa47e89a00714e",
            "48c45ce269b74d4ca0805197e8750f0a",
            "62b33dd91fab4b2fb80e970dd492554e",
            "f6eee0a9ecca415cbd304329a6bbee56",
            "b6bfc17a7da745908c8d2018d4bb363d",
            "72bdb584f9fc4c418f6b05f41c5b2dd7",
            "636850e116894d4c8447f6ba708c601f",
            "b67abc0748434ae8a79c44c54c6fa4b9",
            "13cc47a3e7f14cd98ff220ef3d8a46c7",
            "217c25a8d11e4ee88100a68741585d2e",
            "8357ca43ff344217989b031116511035",
            "6491230e5658495888cd0ed94e8a3eca",
            "ceeb872d412c4af194267229816acbfb",
            "2aee3dbd1ca44f3b8b998662bd0ccf5f",
            "535b0069a9db4e81a4169fbcf045b029",
            "280d48e7c55546fdb3ca257e757abe08",
            "2ad052e4c73448b7a0a6b08e207770ab",
            "78e76b55708b49c999177117eaf30173",
            "38f77572a0274a49aa547d77a8468c26",
            "496268b65ad14ed8b1813dddbb50b3d9",
            "fa9c960f8cb94053a1d9d9d96dd8caec",
            "ba22d0009add46309b15b98e74b804af",
            "76b034def6e542aabf21afc18ec50614",
            "81282b7cb54d45aeaf98b41699674aa8",
            "de69dc91c0254bc68ecdaa30dcabdb83",
            "8d9b1dedfe114b0aaa502cccb5ebe2cc",
            "0a92ddbb6d764b5b9b0e0cb3f2d7de17",
            "9d3b6728564346edb962907ab872c764",
            "806eec90b0d54ff7bb6a5a9facd5cd78",
            "975f653e4a7048d3b74bc3bcff5534ae",
            "390629d366d64cd3a9408364d0912c94",
            "bf966c4722c94113a91fe46e2ab46efe",
            "cd97258189144ed3803677fa6e6e17ae",
            "e1fd562d5dec4634b392ebdc3952371c",
            "3eb65a2d49794020939eece5c78cd84c",
            "218e094db2ea48aaa2293dda9c3f22d8",
            "0901823f4dac48dc9351b9e0d6a5e2e4",
            "c6305c6b700f411a880cb54e8fe83947",
            "d8b7cf380c244da5997d38e60cd20b24",
            "c7d4b017fe094855a8bc1f1e8c450fbd",
            "6bb6aa6bf34a43bd8aca98c6b93a8f71",
            "412e9140c6aa459da0e8181dd713afe1",
            "c9da1aad051d40f8b77080a1c4554d7c",
            "1f34e975ef584236a83ee24fd9559477",
            "5bb6fcb397914e2d952f3d2a75b038b2",
            "9917d19a55864a42b9569f238a88ca4a",
            "7c1eeefed7bf4f08a3993c6666762f96",
            "459a8628d4f9410ca6f8ae6ad8b140ec",
            "73cdacd2d62f44c99906849bb94fa475",
            "167542bbe45546d88a614880f76274ca",
            "bcd42f789bd34042b3dd7ab2c41587b2",
            "b5fb7ac997ed444ebef2eea593fa0b1f",
            "367b1c2ef6f8464789353db67fad4421",
            "7a0172801a40413ab37f68ddb7539ad2",
            "4a8f0eb1fd43455da13d534378db6546",
            "b5eb3a68315f4868a5f1f1ccc93ebc3c",
            "4d79bcbb000e409d99516a908477c56c",
            "863273c5a9984cc4a479aa32946b2817",
            "5605493b02ec44b28e6b9ab6d62fd0d7",
            "8d3a359c1c1d4d0ba7ab2356fc908664",
            "138acd3764ce417bac669d1d0bccbd0a",
            "5648fa19d3aa48959559d8e54bf37424",
            "8b057f6d99cb4685bb3c8141164eaa25",
            "c6044df5fd6147b9a028f8e08f01efef"
          ]
        },
        "id": "vHRJu1zaLXyw",
        "outputId": "8a490789-40e1-41d3-8981-ef9e20576215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.3.15: Fast Llama patching. Transformers: 4.48.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.3.15 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n",
            "Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n",
            "We shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\n",
            "To force `safe_serialization`, set it to `None` instead.\n",
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 3.9G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 6.64 out of 12.67 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 22/32 [00:02<00:00, 10.85it/s]\n",
            "We will save to Disk and not RAM now.\n",
            "100%|██████████| 32/32 [00:44<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving Krish-05/krishna-choudhary-codellama-gguf-quantized/pytorch_model-00001-of-00003.bin...\n",
            "Unsloth: Saving Krish-05/krishna-choudhary-codellama-gguf-quantized/pytorch_model-00002-of-00003.bin...\n",
            "Unsloth: Saving Krish-05/krishna-choudhary-codellama-gguf-quantized/pytorch_model-00003-of-00003.bin...\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Converting llama model. Can use fast conversion = True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m', 'q8_0', 'q5_k_m'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: CMAKE detected. Finalizing some steps for installation.\n",
            "Unsloth: [1] Converting model at Krish-05/krishna-choudhary-codellama-gguf-quantized into f16 GGUF format.\n",
            "The output location will be /content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.F16.gguf\n",
            "This might take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: krishna-choudhary-codellama-gguf-quantized\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00003.bin'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {4096, 32016}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00003.bin'\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00003-of-00003.bin'\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 11008}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {11008, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {4096, 32016}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 16384\n",
            "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 11008\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 32\n",
            "INFO:hf-to-gguf:gguf: rope theta = 1000000\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Setting special token type bos to 1\n",
            "INFO:gguf.vocab:Setting special token type eos to 2\n",
            "INFO:gguf.vocab:Setting special token type unk to 0\n",
            "INFO:gguf.vocab:Setting special token type pad to 0\n",
            "INFO:gguf.vocab:Setting add_bos_token to True\n",
            "INFO:gguf.vocab:Setting add_eos_token to False\n",
            "WARNING:gguf.vocab:No handler for special token type prefix with id 32007 - skipping\n",
            "WARNING:gguf.vocab:No handler for special token type suffix with id 32008 - skipping\n",
            "WARNING:gguf.vocab:No handler for special token type middle with id 32009 - skipping\n",
            "INFO:gguf.vocab:Setting special token type eot to 32010\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.F16.gguf: n_tensors = 291, total_size = 13.5G\n",
            "Writing: 100%|██████████| 13.5G/13.5G [02:27<00:00, 91.5Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
            "main: build = 4915 (99aa304f)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.F16.gguf' to '/content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 33 key-value pairs and 291 tensors from /content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Codellama 7b Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = codellama\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 7B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 16384\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  16:               llama.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  17:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 32016\n",
            "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,32016]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  23:                      tokenizer.ggml.scores arr[f32,32016]   = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,32016]   = [3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  27:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  29:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  30:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  31:                tokenizer.ggml.eot_token_id u32              = 32010\n",
            "llama_model_loader: - kv  32:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  226 tensors\n",
            "[   1/ 291]                        output.weight - [ 4096, 32016,     1,     1], type =    f16, converting to q6_K .. size =   250.12 MiB ->   102.59 MiB\n",
            "[   2/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   3/ 291]                    token_embd.weight - [ 4096, 32016,     1,     1], type =    f16, converting to q4_K .. size =   250.12 MiB ->    70.35 MiB\n",
            "[   4/ 291]                  blk.0.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   5/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   6/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   7/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   8/ 291]                  blk.0.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[   9/ 291]                blk.0.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[  10/ 291]                blk.0.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  11/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  12/ 291]                  blk.0.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  13/ 291]                  blk.1.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  14/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  15/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  16/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  17/ 291]                  blk.1.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  18/ 291]                blk.1.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[  19/ 291]                blk.1.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  20/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  21/ 291]                  blk.1.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  22/ 291]                  blk.2.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  23/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  24/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  25/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  26/ 291]                  blk.2.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  27/ 291]                blk.2.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[  28/ 291]                blk.2.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  29/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  30/ 291]                  blk.2.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  31/ 291]                  blk.3.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  32/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  33/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  34/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  35/ 291]                  blk.3.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  36/ 291]                blk.3.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[  37/ 291]                blk.3.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  38/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  39/ 291]                  blk.3.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  40/ 291]                  blk.4.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  41/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  42/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  43/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  44/ 291]                  blk.4.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  45/ 291]                blk.4.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  46/ 291]                blk.4.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  47/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  48/ 291]                  blk.4.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  49/ 291]                  blk.5.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  50/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  51/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  52/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  53/ 291]                  blk.5.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  54/ 291]                blk.5.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  55/ 291]                blk.5.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  56/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  57/ 291]                  blk.5.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  58/ 291]                  blk.6.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  59/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  60/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  61/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  62/ 291]                  blk.6.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  63/ 291]                blk.6.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[  64/ 291]                blk.6.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  65/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  66/ 291]                  blk.6.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  67/ 291]                  blk.7.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  68/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  69/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  70/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  71/ 291]                  blk.7.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  72/ 291]                blk.7.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  73/ 291]                blk.7.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  74/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  75/ 291]                  blk.7.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  76/ 291]                  blk.8.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  77/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  78/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  79/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  80/ 291]                  blk.8.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  81/ 291]                blk.8.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  82/ 291]                blk.8.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  83/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  84/ 291]                  blk.8.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  85/ 291]                  blk.9.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  86/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  87/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  88/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  89/ 291]                  blk.9.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  90/ 291]                blk.9.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[  91/ 291]                blk.9.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  92/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  93/ 291]                  blk.9.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[  94/ 291]                 blk.10.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  95/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  96/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  97/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  98/ 291]                 blk.10.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  99/ 291]               blk.10.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 100/ 291]               blk.10.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 101/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 102/ 291]                 blk.10.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 103/ 291]                 blk.11.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 104/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 105/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 106/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 107/ 291]                 blk.11.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 108/ 291]               blk.11.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 109/ 291]               blk.11.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 110/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 111/ 291]                 blk.11.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 112/ 291]                 blk.12.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 113/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 114/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 115/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 116/ 291]                 blk.12.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 117/ 291]               blk.12.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 118/ 291]               blk.12.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 119/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 120/ 291]                 blk.12.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 121/ 291]                 blk.13.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 122/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 123/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 124/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 125/ 291]                 blk.13.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 126/ 291]               blk.13.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 127/ 291]               blk.13.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 128/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 129/ 291]                 blk.13.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 130/ 291]                 blk.14.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 131/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 132/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 133/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 134/ 291]                 blk.14.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 135/ 291]               blk.14.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 136/ 291]               blk.14.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 137/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 138/ 291]                 blk.14.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 139/ 291]                 blk.15.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 140/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 141/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 142/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 143/ 291]                 blk.15.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 144/ 291]               blk.15.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 145/ 291]               blk.15.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 146/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 147/ 291]                 blk.15.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 148/ 291]                 blk.16.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 149/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 150/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 151/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 152/ 291]                 blk.16.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 153/ 291]               blk.16.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 154/ 291]               blk.16.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 155/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 156/ 291]                 blk.16.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 157/ 291]                 blk.17.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 158/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 159/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 160/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 161/ 291]                 blk.17.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 162/ 291]               blk.17.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 163/ 291]               blk.17.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 164/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 165/ 291]                 blk.17.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 166/ 291]                 blk.18.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 167/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 168/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 169/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 170/ 291]                 blk.18.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 171/ 291]               blk.18.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 172/ 291]               blk.18.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 173/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 174/ 291]                 blk.18.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 175/ 291]                 blk.19.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 176/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 177/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 178/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 179/ 291]                 blk.19.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 180/ 291]               blk.19.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 181/ 291]               blk.19.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 182/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 183/ 291]                 blk.19.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 184/ 291]                 blk.20.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 185/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 186/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 187/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 188/ 291]                 blk.20.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 189/ 291]               blk.20.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 190/ 291]               blk.20.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 191/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 192/ 291]                 blk.20.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 193/ 291]                 blk.21.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 194/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 195/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 196/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 197/ 291]                 blk.21.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 198/ 291]               blk.21.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 199/ 291]               blk.21.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 200/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 201/ 291]                 blk.21.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 202/ 291]                 blk.22.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 203/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 204/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 205/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 206/ 291]                 blk.22.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 207/ 291]               blk.22.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 208/ 291]               blk.22.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 209/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 210/ 291]                 blk.22.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 211/ 291]                 blk.23.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 212/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 213/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 214/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 215/ 291]                 blk.23.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 216/ 291]               blk.23.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 217/ 291]               blk.23.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 218/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 219/ 291]                 blk.23.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 220/ 291]                 blk.24.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 221/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 222/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 223/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 224/ 291]                 blk.24.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 225/ 291]               blk.24.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 226/ 291]               blk.24.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 227/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 228/ 291]                 blk.24.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 229/ 291]                 blk.25.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 230/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 231/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 232/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 233/ 291]                 blk.25.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 234/ 291]               blk.25.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 235/ 291]               blk.25.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 236/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 237/ 291]                 blk.25.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 238/ 291]                 blk.26.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 239/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 240/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 241/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 242/ 291]                 blk.26.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 243/ 291]               blk.26.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 244/ 291]               blk.26.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 245/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 246/ 291]                 blk.26.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 247/ 291]                 blk.27.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 248/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 249/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 250/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 251/ 291]                 blk.27.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 252/ 291]               blk.27.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 253/ 291]               blk.27.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 254/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 255/ 291]                 blk.27.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 256/ 291]                 blk.28.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 257/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 258/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 259/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 260/ 291]                 blk.28.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 261/ 291]               blk.28.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 262/ 291]               blk.28.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 263/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 264/ 291]                 blk.28.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 265/ 291]                 blk.29.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 266/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 267/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 268/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 269/ 291]                 blk.29.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 270/ 291]               blk.29.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 271/ 291]               blk.29.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 272/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 273/ 291]                 blk.29.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 274/ 291]                 blk.30.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 275/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 276/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 277/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 278/ 291]                 blk.30.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 279/ 291]               blk.30.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 280/ 291]               blk.30.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 281/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 282/ 291]                 blk.30.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 283/ 291]                 blk.31.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 284/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 285/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 286/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 287/ 291]                 blk.31.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 288/ 291]               blk.31.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 289/ 291]               blk.31.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "[ 290/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 291/ 291]                 blk.31.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q4_K .. size =    86.00 MiB ->    24.19 MiB\n",
            "llama_model_quantize_impl: model size  = 12853.27 MB\n",
            "llama_model_quantize_impl: quant size  =  3891.33 MB\n",
            "\n",
            "main: quantize time = 746124.68 ms\n",
            "main:    total time = 746124.68 ms\n",
            "Unsloth: Conversion completed! Output location: /content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.Q4_K_M.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q8_0. This might take 20 minutes...\n",
            "main: build = 4915 (99aa304f)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.F16.gguf' to '/content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.Q8_0.gguf' as Q8_0 using 4 threads\n",
            "llama_model_loader: loaded meta data with 33 key-value pairs and 291 tensors from /content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Codellama 7b Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = codellama\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 7B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 16384\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  16:               llama.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  17:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 32016\n",
            "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,32016]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  23:                      tokenizer.ggml.scores arr[f32,32016]   = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,32016]   = [3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  27:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  29:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  30:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  31:                tokenizer.ggml.eot_token_id u32              = 32010\n",
            "llama_model_loader: - kv  32:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  226 tensors\n",
            "[   1/ 291]                        output.weight - [ 4096, 32016,     1,     1], type =    f16, converting to q8_0 .. size =   250.12 MiB ->   132.88 MiB\n",
            "[   2/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   3/ 291]                    token_embd.weight - [ 4096, 32016,     1,     1], type =    f16, converting to q8_0 .. size =   250.12 MiB ->   132.88 MiB\n",
            "[   4/ 291]                  blk.0.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[   5/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   6/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[   7/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[   8/ 291]                  blk.0.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[   9/ 291]                blk.0.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  10/ 291]                blk.0.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  11/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  12/ 291]                  blk.0.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  13/ 291]                  blk.1.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  14/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  15/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  16/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  17/ 291]                  blk.1.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  18/ 291]                blk.1.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  19/ 291]                blk.1.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  20/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  21/ 291]                  blk.1.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  22/ 291]                  blk.2.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  23/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  24/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  25/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  26/ 291]                  blk.2.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  27/ 291]                blk.2.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  28/ 291]                blk.2.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  29/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  30/ 291]                  blk.2.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  31/ 291]                  blk.3.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  32/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  33/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  34/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  35/ 291]                  blk.3.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  36/ 291]                blk.3.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  37/ 291]                blk.3.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  38/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  39/ 291]                  blk.3.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  40/ 291]                  blk.4.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  41/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  42/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  43/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  44/ 291]                  blk.4.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  45/ 291]                blk.4.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  46/ 291]                blk.4.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  47/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  48/ 291]                  blk.4.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  49/ 291]                  blk.5.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  50/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  51/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  52/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  53/ 291]                  blk.5.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  54/ 291]                blk.5.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  55/ 291]                blk.5.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  56/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  57/ 291]                  blk.5.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  58/ 291]                  blk.6.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  59/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  60/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  61/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  62/ 291]                  blk.6.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  63/ 291]                blk.6.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  64/ 291]                blk.6.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  65/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  66/ 291]                  blk.6.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  67/ 291]                  blk.7.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  68/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  69/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  70/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  71/ 291]                  blk.7.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  72/ 291]                blk.7.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  73/ 291]                blk.7.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  74/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  75/ 291]                  blk.7.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  76/ 291]                  blk.8.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  77/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  78/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  79/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  80/ 291]                  blk.8.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  81/ 291]                blk.8.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  82/ 291]                blk.8.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  83/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  84/ 291]                  blk.8.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  85/ 291]                  blk.9.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  86/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  87/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  88/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  89/ 291]                  blk.9.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  90/ 291]                blk.9.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  91/ 291]                blk.9.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  92/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  93/ 291]                  blk.9.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[  94/ 291]                 blk.10.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  95/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  96/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  97/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  98/ 291]                 blk.10.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  99/ 291]               blk.10.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 100/ 291]               blk.10.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 101/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 102/ 291]                 blk.10.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 103/ 291]                 blk.11.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 104/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 105/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 106/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 107/ 291]                 blk.11.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 108/ 291]               blk.11.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 109/ 291]               blk.11.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 110/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 111/ 291]                 blk.11.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 112/ 291]                 blk.12.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 113/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 114/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 115/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 116/ 291]                 blk.12.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 117/ 291]               blk.12.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 118/ 291]               blk.12.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 119/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 120/ 291]                 blk.12.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 121/ 291]                 blk.13.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 122/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 123/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 124/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 125/ 291]                 blk.13.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 126/ 291]               blk.13.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 127/ 291]               blk.13.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 128/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 129/ 291]                 blk.13.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 130/ 291]                 blk.14.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 131/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 132/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 133/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 134/ 291]                 blk.14.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 135/ 291]               blk.14.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 136/ 291]               blk.14.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 137/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 138/ 291]                 blk.14.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 139/ 291]                 blk.15.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 140/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 141/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 142/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 143/ 291]                 blk.15.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 144/ 291]               blk.15.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 145/ 291]               blk.15.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 146/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 147/ 291]                 blk.15.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 148/ 291]                 blk.16.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 149/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 150/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 151/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 152/ 291]                 blk.16.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 153/ 291]               blk.16.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 154/ 291]               blk.16.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 155/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 156/ 291]                 blk.16.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 157/ 291]                 blk.17.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 158/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 159/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 160/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 161/ 291]                 blk.17.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 162/ 291]               blk.17.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 163/ 291]               blk.17.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 164/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 165/ 291]                 blk.17.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 166/ 291]                 blk.18.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 167/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 168/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 169/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 170/ 291]                 blk.18.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 171/ 291]               blk.18.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 172/ 291]               blk.18.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 173/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 174/ 291]                 blk.18.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 175/ 291]                 blk.19.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 176/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 177/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 178/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 179/ 291]                 blk.19.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 180/ 291]               blk.19.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 181/ 291]               blk.19.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 182/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 183/ 291]                 blk.19.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 184/ 291]                 blk.20.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 185/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 186/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 187/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 188/ 291]                 blk.20.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 189/ 291]               blk.20.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 190/ 291]               blk.20.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 191/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 192/ 291]                 blk.20.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 193/ 291]                 blk.21.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 194/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 195/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 196/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 197/ 291]                 blk.21.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 198/ 291]               blk.21.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 199/ 291]               blk.21.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 200/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 201/ 291]                 blk.21.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 202/ 291]                 blk.22.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 203/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 204/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 205/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 206/ 291]                 blk.22.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 207/ 291]               blk.22.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 208/ 291]               blk.22.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 209/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 210/ 291]                 blk.22.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 211/ 291]                 blk.23.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 212/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 213/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 214/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 215/ 291]                 blk.23.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 216/ 291]               blk.23.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 217/ 291]               blk.23.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 218/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 219/ 291]                 blk.23.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 220/ 291]                 blk.24.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 221/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 222/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 223/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 224/ 291]                 blk.24.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 225/ 291]               blk.24.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 226/ 291]               blk.24.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 227/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 228/ 291]                 blk.24.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 229/ 291]                 blk.25.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 230/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 231/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 232/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 233/ 291]                 blk.25.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 234/ 291]               blk.25.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 235/ 291]               blk.25.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 236/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 237/ 291]                 blk.25.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 238/ 291]                 blk.26.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 239/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 240/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 241/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 242/ 291]                 blk.26.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 243/ 291]               blk.26.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 244/ 291]               blk.26.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 245/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 246/ 291]                 blk.26.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 247/ 291]                 blk.27.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 248/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 249/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 250/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 251/ 291]                 blk.27.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 252/ 291]               blk.27.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 253/ 291]               blk.27.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 254/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 255/ 291]                 blk.27.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 256/ 291]                 blk.28.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 257/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 258/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 259/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 260/ 291]                 blk.28.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 261/ 291]               blk.28.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 262/ 291]               blk.28.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 263/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 264/ 291]                 blk.28.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 265/ 291]                 blk.29.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 266/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 267/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 268/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 269/ 291]                 blk.29.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 270/ 291]               blk.29.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 271/ 291]               blk.29.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 272/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 273/ 291]                 blk.29.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 274/ 291]                 blk.30.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 275/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 276/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 277/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 278/ 291]                 blk.30.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 279/ 291]               blk.30.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 280/ 291]               blk.30.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 281/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 282/ 291]                 blk.30.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 283/ 291]                 blk.31.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 284/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 285/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 286/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 287/ 291]                 blk.31.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 288/ 291]               blk.31.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 289/ 291]               blk.31.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "[ 290/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 291/ 291]                 blk.31.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q8_0 .. size =    86.00 MiB ->    45.69 MiB\n",
            "llama_model_quantize_impl: model size  = 12853.27 MB\n",
            "llama_model_quantize_impl: quant size  =  6828.77 MB\n",
            "\n",
            "main: quantize time = 137052.87 ms\n",
            "main:    total time = 137052.87 ms\n",
            "Unsloth: Conversion completed! Output location: /content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.Q8_0.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q5_k_m. This might take 20 minutes...\n",
            "main: build = 4915 (99aa304f)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.F16.gguf' to '/content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.Q5_K_M.gguf' as Q5_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 33 key-value pairs and 291 tensors from /content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Codellama 7b Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = codellama\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 7B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 16384\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  16:               llama.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  17:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 32016\n",
            "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,32016]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  23:                      tokenizer.ggml.scores arr[f32,32016]   = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,32016]   = [3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  27:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  29:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  30:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  31:                tokenizer.ggml.eot_token_id u32              = 32010\n",
            "llama_model_loader: - kv  32:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  226 tensors\n",
            "[   1/ 291]                        output.weight - [ 4096, 32016,     1,     1], type =    f16, converting to q6_K .. size =   250.12 MiB ->   102.59 MiB\n",
            "[   2/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   3/ 291]                    token_embd.weight - [ 4096, 32016,     1,     1], type =    f16, converting to q5_K .. size =   250.12 MiB ->    85.98 MiB\n",
            "[   4/ 291]                  blk.0.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[   5/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   6/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[   7/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[   8/ 291]                  blk.0.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[   9/ 291]                blk.0.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[  10/ 291]                blk.0.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  11/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  12/ 291]                  blk.0.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  13/ 291]                  blk.1.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  14/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  15/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  16/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  17/ 291]                  blk.1.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  18/ 291]                blk.1.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[  19/ 291]                blk.1.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  20/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  21/ 291]                  blk.1.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  22/ 291]                  blk.2.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  23/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  24/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  25/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  26/ 291]                  blk.2.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  27/ 291]                blk.2.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[  28/ 291]                blk.2.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  29/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  30/ 291]                  blk.2.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  31/ 291]                  blk.3.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  32/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  33/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  34/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  35/ 291]                  blk.3.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  36/ 291]                blk.3.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[  37/ 291]                blk.3.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  38/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  39/ 291]                  blk.3.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  40/ 291]                  blk.4.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  41/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  42/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  43/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  44/ 291]                  blk.4.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  45/ 291]                blk.4.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  46/ 291]                blk.4.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  47/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  48/ 291]                  blk.4.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  49/ 291]                  blk.5.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  50/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  51/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  52/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  53/ 291]                  blk.5.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  54/ 291]                blk.5.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  55/ 291]                blk.5.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  56/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  57/ 291]                  blk.5.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  58/ 291]                  blk.6.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  59/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  60/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  61/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  62/ 291]                  blk.6.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  63/ 291]                blk.6.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[  64/ 291]                blk.6.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  65/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  66/ 291]                  blk.6.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  67/ 291]                  blk.7.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  68/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  69/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  70/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  71/ 291]                  blk.7.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  72/ 291]                blk.7.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  73/ 291]                blk.7.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  74/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  75/ 291]                  blk.7.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  76/ 291]                  blk.8.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  77/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  78/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  79/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  80/ 291]                  blk.8.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  81/ 291]                blk.8.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  82/ 291]                blk.8.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  83/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  84/ 291]                  blk.8.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  85/ 291]                  blk.9.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  86/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  87/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  88/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  89/ 291]                  blk.9.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  90/ 291]                blk.9.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[  91/ 291]                blk.9.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  92/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  93/ 291]                  blk.9.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[  94/ 291]                 blk.10.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  95/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  96/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  97/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  98/ 291]                 blk.10.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  99/ 291]               blk.10.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 100/ 291]               blk.10.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 101/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 102/ 291]                 blk.10.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 103/ 291]                 blk.11.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 104/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 105/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 106/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 107/ 291]                 blk.11.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 108/ 291]               blk.11.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 109/ 291]               blk.11.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 110/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 111/ 291]                 blk.11.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 112/ 291]                 blk.12.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 113/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 114/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 115/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 116/ 291]                 blk.12.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 117/ 291]               blk.12.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 118/ 291]               blk.12.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 119/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 120/ 291]                 blk.12.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 121/ 291]                 blk.13.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 122/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 123/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 124/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 125/ 291]                 blk.13.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 126/ 291]               blk.13.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 127/ 291]               blk.13.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 128/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 129/ 291]                 blk.13.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 130/ 291]                 blk.14.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 131/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 132/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 133/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 134/ 291]                 blk.14.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 135/ 291]               blk.14.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 136/ 291]               blk.14.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 137/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 138/ 291]                 blk.14.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 139/ 291]                 blk.15.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 140/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 141/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 142/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 143/ 291]                 blk.15.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 144/ 291]               blk.15.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 145/ 291]               blk.15.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 146/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 147/ 291]                 blk.15.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 148/ 291]                 blk.16.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 149/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 150/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 151/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 152/ 291]                 blk.16.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 153/ 291]               blk.16.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 154/ 291]               blk.16.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 155/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 156/ 291]                 blk.16.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 157/ 291]                 blk.17.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 158/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 159/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 160/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 161/ 291]                 blk.17.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 162/ 291]               blk.17.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 163/ 291]               blk.17.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 164/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 165/ 291]                 blk.17.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 166/ 291]                 blk.18.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 167/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 168/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 169/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 170/ 291]                 blk.18.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 171/ 291]               blk.18.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 172/ 291]               blk.18.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 173/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 174/ 291]                 blk.18.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 175/ 291]                 blk.19.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 176/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 177/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 178/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 179/ 291]                 blk.19.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 180/ 291]               blk.19.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 181/ 291]               blk.19.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 182/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 183/ 291]                 blk.19.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 184/ 291]                 blk.20.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 185/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 186/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 187/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 188/ 291]                 blk.20.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 189/ 291]               blk.20.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 190/ 291]               blk.20.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 191/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 192/ 291]                 blk.20.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 193/ 291]                 blk.21.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 194/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 195/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 196/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 197/ 291]                 blk.21.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 198/ 291]               blk.21.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 199/ 291]               blk.21.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 200/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 201/ 291]                 blk.21.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 202/ 291]                 blk.22.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 203/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 204/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 205/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 206/ 291]                 blk.22.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 207/ 291]               blk.22.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 208/ 291]               blk.22.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 209/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 210/ 291]                 blk.22.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 211/ 291]                 blk.23.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 212/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 213/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 214/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 215/ 291]                 blk.23.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 216/ 291]               blk.23.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 217/ 291]               blk.23.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 218/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 219/ 291]                 blk.23.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 220/ 291]                 blk.24.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 221/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 222/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 223/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 224/ 291]                 blk.24.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 225/ 291]               blk.24.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 226/ 291]               blk.24.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 227/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 228/ 291]                 blk.24.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 229/ 291]                 blk.25.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 230/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 231/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 232/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 233/ 291]                 blk.25.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 234/ 291]               blk.25.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 235/ 291]               blk.25.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 236/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 237/ 291]                 blk.25.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 238/ 291]                 blk.26.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 239/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 240/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 241/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 242/ 291]                 blk.26.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 243/ 291]               blk.26.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 244/ 291]               blk.26.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 245/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 246/ 291]                 blk.26.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 247/ 291]                 blk.27.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 248/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 249/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 250/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 251/ 291]                 blk.27.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 252/ 291]               blk.27.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 253/ 291]               blk.27.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 254/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 255/ 291]                 blk.27.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 256/ 291]                 blk.28.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 257/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 258/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 259/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 260/ 291]                 blk.28.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 261/ 291]               blk.28.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 262/ 291]               blk.28.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 263/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 264/ 291]                 blk.28.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 265/ 291]                 blk.29.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 266/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 267/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 268/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 269/ 291]                 blk.29.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 270/ 291]               blk.29.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 271/ 291]               blk.29.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 272/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 273/ 291]                 blk.29.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 274/ 291]                 blk.30.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 275/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 276/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 277/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 278/ 291]                 blk.30.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 279/ 291]               blk.30.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 280/ 291]               blk.30.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 281/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 282/ 291]                 blk.30.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 283/ 291]                 blk.31.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 284/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 285/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 286/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 287/ 291]                 blk.31.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 288/ 291]               blk.31.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, converting to q6_K .. size =    86.00 MiB ->    35.27 MiB\n",
            "[ 289/ 291]               blk.31.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "[ 290/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 291/ 291]                 blk.31.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, converting to q5_K .. size =    86.00 MiB ->    29.56 MiB\n",
            "llama_model_quantize_impl: model size  = 12853.27 MB\n",
            "llama_model_quantize_impl: quant size  =  4560.96 MB\n",
            "\n",
            "main: quantize time = 637489.79 ms\n",
            "main:    total time = 637489.79 ms\n",
            "Unsloth: Conversion completed! Output location: /content/Krish-05/krishna-choudhary-codellama-gguf-quantized/unsloth.Q5_K_M.gguf\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b0dbda896aa4a53b8920234fb9c6aea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.Q4_K_M.gguf:   0%|          | 0.00/4.08G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "217c25a8d11e4ee88100a68741585d2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved GGUF to https://huggingface.co/Krish-05/krishna-choudhary-codellama-gguf-quantized\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa9c960f8cb94053a1d9d9d96dd8caec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.Q8_0.gguf:   0%|          | 0.00/7.16G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf966c4722c94113a91fe46e2ab46efe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved GGUF to https://huggingface.co/Krish-05/krishna-choudhary-codellama-gguf-quantized\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9da1aad051d40f8b77080a1c4554d7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.Q5_K_M.gguf:   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a0172801a40413ab37f68ddb7539ad2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved GGUF to https://huggingface.co/Krish-05/krishna-choudhary-codellama-gguf-quantized\n"
          ]
        }
      ]
    }
  ]
}